# AI Sales Qualification Assistant for Energy Storage

This repository contains a **portfolio-grade MVP** of an AI-powered assistant
designed to support the **first response and qualification stage** of the sales process
for **energy storage systems (BESS)**.

The project focuses on automating the preparation of a **first reply to a customer inquiry**:
understanding the message, identifying what information is already known,
and generating a clear, professional response asking only for missing details.

> Disclaimer
> This is a **personal portfolio project**.
> It uses **only synthetic or public data** and does **not** contain any confidential,
> proprietary, or internal information from any company.

---

## Problem

Sales engineers and technical sales teams often receive customer inquiries
that are **incomplete, non-technical, or ambiguous**.

Typical challenges:
- Customers describe needs in natural language, not technical parameters
- Important details (capacity, power, constraints) are missing
- First responses take time and are repetitive
- Sales teams risk asking redundant or irrelevant questions

---

## Solution (MVP Scope)

This MVP demonstrates a realistic **AI-assisted sales qualification workflow**:

1. A customer email is analysed to extract structured signals (facts).
2. Decision criteria are evaluated to determine which inputs are
   already known and which are still missing.
3. Only missing information is requested in the reply.
4. Product documentation is used as **high-level contextual grounding (RAG)**.
5. A draft response email is generated using a **local LLM**.

The assistant **does not** generate prices or final offers.
Its role is to **support the salesperson**, not replace them.

---

## Features & Capabilities

**Signal Extraction**
- LLM-based parsing of customer emails into structured JSON facts
- Extracts explicitly stated information such as capacity references, power hints, location constraints, and stated use cases
- Configurable extraction prompts

**RAG Pipeline**
- ChromaDB vector database for product documentation
- Sentence-transformers embeddings (all-MiniLM-L6-v2)
- Human-readable context generation from ranked documents
- Synthetic BESS product variants and accessories database

**Qualification Logic**
- YAML-based decision criteria configuration
- Multi-stage prompt construction with known facts and RAG context
- LLM-assisted identification of missing qualification inputs

**Local LLM Inference**
- Ollama runtime integration (no cloud dependency)
- Configurable model selection (default: qwen2.5:1.5b)
- Subprocess-based stable execution on Windows

**Demo & Testing**
- 3 example customer emails with varying complexity
- Sample outputs demonstrating end-to-end workflow
- Configurable via environment variables

---

## Architecture (High Level)

- **Signal extraction**
  LLM-based parsing of customer emails into structured facts

- **Decision criteria evaluation**
  AI-assisted evaluation of which qualification inputs are missing

- **RAG (Retrieval-Augmented Generation)**
  Synthetic product documentation indexed locally and used as contextual background

- **LLM generation**
  Local inference using Ollama (no cloud dependency)

---

## Technology Stack

**Core Dependencies**
- Python 3.11+
- Poetry (dependency management)
- Ollama (local LLM runtime)

**Key Libraries**
- `chromadb` â€“ vector database for RAG
- `sentence-transformers` â€“ embedding generation
- `PyYAML` â€“ decision criteria configuration

---

## Repository Structure

```
data/                           â€“ synthetic product documentation (BESS variants)
â”œâ”€â”€ bess_small_modular/         â€“ modular BESS system specs
â””â”€â”€ accessories/                â€“ wireless communication and monitoring accessories

queries/                        â€“ example customer emails
â”œâ”€â”€ client_email_01.txt         â€“ basic capacity inquiry
â”œâ”€â”€ client_email_02.txt         â€“ multi-site deployment request
â””â”€â”€ client_email_03.txt         â€“ accessory/add-on request

prompts/                        â€“ prompt templates
â”œâ”€â”€ extract_signals_prompt.md   â€“ signal extraction instructions
â””â”€â”€ qualification_prompt.md     â€“ main qualification prompt template

scripts/                        â€“ core MVP logic and RAG pipeline
â”œâ”€â”€ run_qualification.py        â€“ main end-to-end qualification workflow
â”œâ”€â”€ extract_signals.py          â€“ LLM-based signal extraction
â”œâ”€â”€ rag_index.py                â€“ index product documentation into ChromaDB
â”œâ”€â”€ rag_search.py               â€“ retrieve relevant context from RAG
â””â”€â”€ rag_query.py                â€“ interactive RAG query tool

config/                         â€“ decision criteria definitions (YAML)
â””â”€â”€ decision_criteria_bess.yaml â€“ qualification requirements for BESS sales

demo_output/                    â€“ example generated outputs
â””â”€â”€ mail01_*.md                 â€“ sample qualification responses

docs/                           â€“ conceptual documentation
tests/                          â€“ test suite (pytest)
chroma_db/                      â€“ local vector database (gitignored)
```

---

## RAG in This MVP

A local RAG pipeline (Chroma + embeddings) is implemented and demonstrated.

In this MVP:
- RAG provides **high-level product context** only
- It does **not** influence the questions asked to the customer
- It can be used to demonstrate how different emails map to different solution variants

This separation is intentional and reflects real sales workflows.

This design choice intentionally separates qualification logic from product selection,
reflecting how real sales engineers operate in early-stage conversations.

---

## What This MVP Is Not

- Not a pricing engine
- Not an automated offer generator
- Not a replacement for sales engineers
- Not a production-ready system

---

## â–¶ Running the Demo (Local)

### Prerequisites
- Python 3.11+
- Poetry
- Ollama (local LLM runtime)

### Setup
```bash
git clone https://github.com/yourusername/ai-offer-assistant.git
cd ai-offer-assistant
poetry install
```

Pull a local model:
```bash
ollama pull qwen2.5:3b
```

### Demo Workflow

Index product documentation (RAG):
```bash
python scripts/rag_index.py
```

Run end-to-end qualification:
```bash
python scripts/run_qualification.py
```

Try different inputs:
```bash
export QUAL_EMAIL_FILE=client_email_02.txt
export OLLAMA_MODEL=qwen2.5:3b
python scripts/run_qualification.py
```

---

## Example Output

The outputs are intended as decision support for a human salesperson,
not as fully automated customer communication.

Sample outputs are available in [`demo_output/`](demo_output/):
- Signal extraction results (structured JSON)
- RAG context retrieval (ranked documents)
- Final qualification email drafts

These demonstrate the system's ability to:
- Parse ambiguous customer requests
- Identify missing technical parameters
- Generate professional, context-aware responses

---

## ðŸ‘¤ Author

Joanna WidziÅ„ska
Personal portfolio project
Focus: AI-assisted sales workflows in energy storage
